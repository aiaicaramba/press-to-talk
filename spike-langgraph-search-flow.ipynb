{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike LangGraph (Re)Search Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq langchain langgraph langchain_openai langchainhub langsmith duckduckgo-search beautifulsoup4 gradio ipywidgets tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Commented out if set in .env file\n",
    "# os.environ[\"OPENAI_API_KEY\"] = 'lm-studio' # Set to 'lm-studio' for local LMStudio inference\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = ''\n",
    "\n",
    "# Set LangSmith tracing and project name reference variables\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true' \n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = '20240422-Spike LangGraph Local LLM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonvanbokhorst/repos/press-to-talk/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import functools, operator, requests, os, json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "#llm = ChatOpenAI(model=\"NA\", base_url=\"http://192.168.50.116:8000/v1\") # Use for local inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internet Search Tool (TavilySearch)\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "internet_search = TavilySearchResults(max_results=3)\n",
    "\n",
    "# Process Content Tool (BS4)\n",
    "@tool(\"process_content\", return_direct=False)\n",
    "def process_content(url: str) -> str:\n",
    "    \"\"\"Processes content from a webpage.\"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "# Tool set\n",
    "tools = [internet_search, process_content]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for creating agents\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ])\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "# Define agent nodes\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent Supervisor\n",
    "members = [\"Web_Searcher\", \"Insight_Researcher\"]\n",
    "system_prompt = (\n",
    "    \"As a supervisor, your role is to oversee a dialogue between these\"\n",
    "    \" workers: {members}. Based on the user's request,\"\n",
    "    \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "    \" executing a specific task and reporting back their findings and progress. Once all tasks are complete,\"\n",
    "    \" indicate with 'FINISH'.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}] }},\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "]).partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (prompt | llm.bind_functions(functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Search Agent\n",
    "search_agent = create_agent(llm, tools, \"You are a web searcher. Search the internet for information.\")\n",
    "search_node = functools.partial(agent_node, agent=search_agent, name=\"Web_Searcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Web Insight Researcher Agent\n",
    "insights_research_agent = create_agent(llm, tools, \n",
    "        \"\"\"You are a Insight Researcher. Do step by step. \n",
    "        Based on the provided content first identify the list of topics,\n",
    "        then search internet for each topic one by one\n",
    "        and finally find insights for each topic one by one.\n",
    "        Include the insights and sources in the final response\n",
    "        \"\"\")\n",
    "\n",
    "insights_research_node = functools.partial(agent_node, agent=insights_research_agent, name=\"Insight_Researcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Web_Searcher\", search_node)\n",
    "workflow.add_node(\"Insight_Researcher\", insights_research_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define edges\n",
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"], conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Compile the workflow graph\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Web_Searcher'}}\n",
      "----\n",
      "{'Web_Searcher': {'messages': [HumanMessage(content=\"I have summarized the content from the sources on the latest veal ear tag technology trends in 2024:\\n\\n1. **Smart Ear Tags for Livestock Market Insight**:\\n   - Market Overview: Smart ear tags utilize RFID technology to collect real-time data about animals' behavior, health, and location.\\n   - Market Growth: The market is projected to experience significant growth with a focus on efficiency and IoT adoption.\\n   - Market Trends: Cloud-based smart ear tags are preferred for easy data management. Advanced features like temperature monitoring are becoming popular.\\n\\n2. **Ear Tags in Beef Industry**:\\n   - Merck's SenseHub Feedlot technology tracks animal health via ear tags, providing real-time data on temperature and behavior.\\n   - Database Reporting: The system helps diagnose illness faster by analyzing abnormal behaviors and changes in animal temperatures.\\n\\n3. **Electronic Ear Tags Market Research Report**:\\n   - Market Growth: Electronic ear tags are rapidly growing in the livestock industry for monitoring animal health and behavior.\\n   - Market Segmentation: Tags are used for identification in various markets like pet management, livestock tracking, and conservation efforts.\\n   - Market Players: Companies like Allflex, Ceres Tag, and Moocall are leading in providing advanced tracking solutions.\\n\\nInsight researchers can provide further insights on the market trends, growth opportunities, challenges, and the impact of these technologies on the livestock industry.\", name='Web_Searcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'Insight_Researcher'}}\n",
      "----\n",
      "{'Insight_Researcher': {'messages': [HumanMessage(content=\"### Insights on Latest Veal Ear Tag Technology Trends in 2024:\\n\\n#### 1. Smart Ear Tags for Livestock Market:\\n- **Market Overview**: Smart ear tags use RFID technology for real-time data on animal behavior, health, and location.\\n- **Market Growth**: Significant growth expected with a focus on efficiency and IoT adoption.\\n- **Market Trends**: Cloud-based smart ear tags are preferred for easy data management, with features like temperature monitoring gaining popularity.\\n- **Sources**: [LinkedIn](https://www.linkedin.com/pulse/smart-ear-tags-livestock-market-2024-oocve), [Global Info Research](https://www.globalinforesearch.com/reports/1692809/smart-ear-tags-for-livestock), [Cognitive Market Research](https://www.cognitivemarketresearch.com/smart-ear-tags-for-livestock-market-report)\\n\\n#### Insights:\\n- The adoption of cloud-based smart ear tags is a growing trend in livestock management, enabling efficient data collection and analysis.\\n- The increasing demand for advanced features like temperature monitoring indicates a shift towards precision livestock farming.\\n- Companies in the livestock industry can capitalize on this trend by investing in IoT solutions for improved animal welfare and productivity.\\n\\n---\\n\\n#### 2. Ear Tags in Beef Industry:\\n- **Technology**: Merck's SenseHub Feedlot technology tracks animal health via ear tags, providing real-time data on temperature and behavior.\\n- **Market Impact**: USDA regulations require official RFID ear tags for animal traceability compliance.\\n- **Market Insights**: Rising preference for cloud-based smart ear tags in the beef industry.\\n- **Sources**: [WYLR](https://www.wylr.net/2024/01/19/ear-tags-are-the-focus-of-emerging-technology-in-beef-industry/), [Beef Magazine](https://www.beefmagazine.com/cattle-health/usda-official-id-to-be-rfid-ear-tag), [Medium](https://medium.com/@patriciahanson2013/smart-ear-tags-for-livestock-market-insight-market-trends-growth-forecasted-from-2024-to-2031-f4610ad50d44)\\n\\n#### Insights:\\n- The adoption of RFID ear tags in the beef industry is essential for compliance with regulatory standards and improving traceability.\\n- Cloud-based smart ear tags offer enhanced data management capabilities, enabling better monitoring and management of animal health in feedlots.\\n- The shift towards technology-driven solutions in the beef industry presents opportunities for improving operational efficiency and animal welfare.\\n\\n---\\n\\n#### 3. Electronic Ear Tags Market Research Report:\\n- **Market Growth**: Rapid growth of electronic ear tags for monitoring animal health and behavior.\\n- **Market Segmentation**: Tags used for identification in pet management, livestock tracking, and conservation efforts.\\n- **Key Players**: Allflex, Ceres Tag, and Moocall are leading providers of advanced tracking solutions.\\n- **Sources**: [ENR Market Research](https://www.enrmarketresearch.com/global-animal-breeding-electronic-ear-tags-2024-545-7921248), [24 Market Research](https://www.24marketresearch.com/agriculture/7935024/global-animal-electronic-ear-tags-2024-720), [Cognitive Market Research](https://www.cognitivemarketresearch.com/electronic-ear-tags-market-report)\\n\\n#### Insights:\\n- The electronic ear tags market is witnessing steady growth across various sectors, indicating a broad application in animal identification and tracking.\\n- Companies like Allflex, Ceres Tag, and Moocall are at the forefront of providing innovative tracking solutions, driving technological advancements in the livestock industry.\\n- The market segmentation highlights the versatility of electronic ear tags, catering to diverse needs from livestock management to wildlife conservation efforts.\\n\\nThese insights provide a comprehensive overview of the latest veal ear tag technology trends in 2024 and their implications for the livestock industry.\", name='Insight_Researcher')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Run the graph\n",
    "for s in graph.stream({\n",
    "    \"messages\": [HumanMessage(content=\"\"\"Search for the latest veal ear tag technology trends in 2024,\n",
    "            summarize the content. After summarise pass it on to insight researcher\n",
    "            to provide insights for each topic\"\"\")]\n",
    "}):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_response = graph.invoke({\n",
    "#     \"messages\": [HumanMessage(\n",
    "#         content=\"\"\"Search for the latest veal ear tag technology trends in 2024,\n",
    "#                 summarize the content\n",
    "#                 and provide insights for each topic.\"\"\")]\n",
    "# })\n",
    "\n",
    "# print(final_response['messages'][1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
